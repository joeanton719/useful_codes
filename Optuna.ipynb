{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    cat_iterations = trial.suggest_int(\"cat_iterations\", 10, 2500)\n",
    "    cat_depth = trial.suggest_int(\"cat_depth\", 1, 7)\n",
    "    cat_learning_rate = trial.suggest_float(\"cat_learning_rate\", 0.0001, 0.4)\n",
    "    cat_boosting_type = trial.suggest_categorical(\"cat_boosting_type\", ['Ordered', 'Plain'])\n",
    "    cat_l2_leaf_reg = trial.suggest_float(\"cat_l2_leaf_reg\", 0.1, 100.0)\n",
    "    cat_border_count = trial.suggest_int(\"cat_border_count\", 5, 200)\n",
    "    \n",
    "    model = CatBoostClassifier(verbose = False, \n",
    "                               loss_function='CrossEntropy', \n",
    "                               eval_metric='TotalF1', \n",
    "                               random_seed = seed, \n",
    "                               iterations = cat_iterations, \n",
    "                               depth = cat_depth, \n",
    "                               learning_rate = cat_learning_rate, \n",
    "                               boosting_type = cat_boosting_type, \n",
    "                               l2_leaf_reg = cat_l2_leaf_reg, \n",
    "                               border_count = cat_border_count)\n",
    "\n",
    "    cv_score = cross_val_score(model, \n",
    "#                                X_train, \n",
    "#                                y_train, \n",
    "                               cv=StratifiedKFold(n_splits=10, random_state=seed, shuffle=True),\n",
    "                               scoring='roc_auc')\n",
    "    score = cv_score.mean()\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.CmaEsSampler(warn_independent_sampling = False)\n",
    ") #TPESampler(seed = seed, multivariate = True)\n",
    "\n",
    "study.optimize(objective, \n",
    "               n_trials=120, \n",
    "               n_jobs = -1, \n",
    "               show_progress_bar = True)\n",
    "print()\n",
    "print(f'Best Score: {study.best_value*100:.3f} %')\n",
    "print()\n",
    "print(f'Best Params:')\n",
    "print(study.best_params)\n",
    "\n",
    "results = study.trials_dataframe()\n",
    "results['value'].sort_values().reset_index(drop=True).plot();\n",
    "plt.title('Convergence plot');\n",
    "plt.xlabel('Iteration');\n",
    "plt.ylabel('Score');\n",
    "\n",
    "chosen_param = {\n",
    "    i.replace(\"cat_\", \"\"):j for i, j in zip(study.best_params.keys(), study.best_params.values())\n",
    "}\n",
    "print()\n",
    "print(chosen_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regulaized Greedy Forest (RGF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "    rgf_algorithm = trial.suggest_categorical(\"rgf_algorithm\", ['RGF', 'RGF_Opt', 'RGF_Sib'])\n",
    "    rgf_l2 = trial.suggest_float(\"rgf_l2\", 0.0001, 1)\n",
    "    rgf_learning_rate  = trial.suggest_float(\"rgf_learning_rate\", 0.001, 0.5)\n",
    "    rgf_loss = trial.suggest_categorical(\"rgf_loss\", ['LS', 'Log', 'Expo'])\n",
    "    rgf_max_leaf = trial.suggest_int(\"rgf_max_leaf\", 1000, 10000)\n",
    "    rgf_calc_prob = trial.suggest_categorical(\"rgf_calc_prob\", [\"softmax\", \"sigmoid\"])\n",
    "    rgf_min_samples_leaf = trial.suggest_int(\"rgf_min_samples_leaf\", 1, 20)\n",
    "    rgf_reg_depth =  trial.suggest_float(\"rgf_reg_depth\", 1.0, 5.0)\n",
    "    rgf_test_interval = trial.suggest_int(\"rgf_test_interval\", 100, 600)\n",
    "    \n",
    "    model = RGFClassifier(algorithm = rgf_algorithm, \n",
    "                          l2 = rgf_l2, \n",
    "                          learning_rate = rgf_learning_rate, \n",
    "                          loss = rgf_loss, \n",
    "                          max_leaf = rgf_max_leaf, \n",
    "                          calc_prob = rgf_calc_prob, \n",
    "                          min_samples_leaf = rgf_min_samples_leaf, \n",
    "                          reg_depth = rgf_reg_depth, \n",
    "                          test_interval = rgf_test_interval)\n",
    "\n",
    "    cv_score = cross_val_score(model, \n",
    "#                                X_train_pars, \n",
    "#                                y_train, \n",
    "                               cv=StratifiedKFold(n_splits=10, random_state=seed, shuffle=True),\n",
    "                               scoring='roc_auc')\n",
    "    \n",
    "    score = cv_score.mean()\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.CmaEsSampler(warn_independent_sampling = False)\n",
    ") #TPESampler(seed = seed, multivariate = True)\n",
    "\n",
    "study.optimize(objective, \n",
    "               n_trials=120, \n",
    "               n_jobs = -1, \n",
    "               show_progress_bar = True)\n",
    "print()\n",
    "print(f'Best Score: {study.best_value*100:.3f} %')\n",
    "print()\n",
    "print(f'Best Params:')\n",
    "print(study.best_params)\n",
    "\n",
    "results = study.trials_dataframe()\n",
    "results['value'].sort_values().reset_index(drop=True).plot();\n",
    "plt.title('Convergence plot');\n",
    "plt.xlabel('Iteration');\n",
    "plt.ylabel('Score');\n",
    "\n",
    "chosen_param = {\n",
    "    i.replace(\"rgf_\", \"\"):j for i, j in zip(study.best_params.keys(), study.best_params.values())\n",
    "}\n",
    "print()\n",
    "print(chosen_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanced RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "    balRF_n_estimators = trial.suggest_int(\"balRF_n_estimators\", 10, 1500)\n",
    "    balRF_criterion = trial.suggest_categorical(\"balRF_criterion\", ['gini', 'entropy'])\n",
    "    balRF_max_depth = trial.suggest_int(\"balRF_max_depth\", 1, 7)\n",
    "    balRF_min_samples_split = trial.suggest_float(\"balRF_min_samples_split\", 0.0001, 0.999)\n",
    "    balRF_min_samples_leaf = trial.suggest_int(\"balRF_min_samples_leaf\", 1, 30)\n",
    "    balRF_max_features = trial.suggest_categorical(\"balRF_max_features\", ['sqrt', 'log2'])\n",
    "    balRF_ccp_alpha = trial.suggest_float(\"balRF_ccp_alpha\", 0.0001, 0.035)\n",
    "    balRF_bootstrap = trial.suggest_categorical(\"balRF_bootstrap\", [True, False])\n",
    "    balRF_replacement = trial.suggest_categorical(\"balRF_replacement\", [True, False])\n",
    "    balRF_class_weight = trial.suggest_categorical(\"balRF_class_weight\", ['balanced', 'balanced_subsample'])\n",
    "    balRF_max_samples = trial.suggest_float(\"balRF_max_samples\", 0.1, 0.999)\n",
    "    \n",
    "    model = BalancedRandomForestClassifier(random_state = seed, \n",
    "                                           n_jobs = -1, \n",
    "                                           n_estimators = balRF_n_estimators, \n",
    "                                           criterion = balRF_criterion, \n",
    "                                           max_depth = balRF_max_depth, \n",
    "                                           min_samples_split = balRF_min_samples_split, \n",
    "                                           min_samples_leaf = balRF_min_samples_leaf, \n",
    "                                           max_features = balRF_max_features, \n",
    "                                           ccp_alpha = balRF_ccp_alpha, \n",
    "                                           bootstrap = balRF_bootstrap, \n",
    "                                           replacement = balRF_replacement, \n",
    "                                           class_weight = balRF_class_weight, \n",
    "                                           max_samples = balRF_max_samples)\n",
    "\n",
    "    cv_score = cross_val_score(model, \n",
    "                               X_train_pars, \n",
    "                               y_train, \n",
    "                               cv=StratifiedKFold(n_splits=10, random_state=seed, shuffle=True),\n",
    "                               scoring='roc_auc')\n",
    "    score = cv_score.mean()\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.CmaEsSampler(warn_independent_sampling = False)\n",
    ") #TPESampler(seed = seed, multivariate = True)\n",
    "\n",
    "study.optimize(objective, \n",
    "               n_trials=120, \n",
    "               n_jobs = -1, \n",
    "               show_progress_bar = True)\n",
    "print()\n",
    "print(f'Best Score: {study.best_value*100:.3f} %')\n",
    "print()\n",
    "print(f'Best Params:')\n",
    "print(study.best_params)\n",
    "\n",
    "results = study.trials_dataframe()\n",
    "results['value'].sort_values().reset_index(drop=True).plot();\n",
    "plt.title('Convergence plot');\n",
    "plt.xlabel('Iteration');\n",
    "plt.ylabel('Score');\n",
    "\n",
    "chosen_param = {\n",
    "    i.replace(\"balRF_\", \"\"):j for i, j in zip(study.best_params.keys(), study.best_params.values())\n",
    "}\n",
    "print()\n",
    "print(chosen_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    gbc_loss = trial.suggest_categorical(\"gbc_loss\", ['deviance', 'exponential'])\n",
    "    gbc_learning_rate = trial.suggest_float(\"gbc_learning_rate\", 0.001, 0.5)\n",
    "    gbc_n_estimators = trial.suggest_int(\"gbc_n_estimators\", 10, 2000)\n",
    "    gbc_min_samples_split = trial.suggest_int(\"gbc_min_samples_split\", 2, 100)\n",
    "    gbc_min_samples_leaf = trial.suggest_int(\"gbc_min_samples_leaf\", 1, 10)\n",
    "    gbc_max_depth = trial.suggest_int(\"gbc_max_depth\", 1, 7)\n",
    "    gbc_max_features = trial.suggest_categorical(\"gbc_max_features\", ['sqrt', 'log2'])\n",
    "    gbc_ccp_alpha = trial.suggest_float(\"gbc_ccp_alpha\", 0.0, 0.035)\n",
    "    gbc_subsample = trial.suggest_float(\"gbc_subsample\", 0.5, 1.0)\n",
    "    gbc_criterion = trial.suggest_categorical(\"gbc_criterion\", ['friedman_mse', 'mse', 'mae'])\n",
    "    \n",
    "    \n",
    "    model = GradientBoostingClassifier(random_state = seed, \n",
    "                                       loss = gbc_loss, \n",
    "                                       learning_rate = gbc_learning_rate, \n",
    "                                       n_estimators = gbc_n_estimators, \n",
    "                                       min_samples_split = gbc_min_samples_split, \n",
    "                                       min_samples_leaf = gbc_min_samples_leaf, \n",
    "                                       max_depth = gbc_max_depth, \n",
    "                                       max_features = gbc_max_features, \n",
    "                                       ccp_alpha = gbc_ccp_alpha, \n",
    "                                       subsample = gbc_subsample, \n",
    "                                       criterion = gbc_criterion)\n",
    "    \n",
    "    cv_score = cross_val_score(model, \n",
    "                               X_train_pars, \n",
    "                               y_train, \n",
    "                               cv=StratifiedKFold(n_splits=10, random_state=seed, shuffle=True),\n",
    "                               scoring='roc_auc')\n",
    "    \n",
    "    score = cv_score.mean()\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.CmaEsSampler(warn_independent_sampling = False)\n",
    ") #TPESampler(seed = seed, multivariate = True)\n",
    "\n",
    "study.optimize(objective, \n",
    "               n_trials=120, \n",
    "               n_jobs = -1, \n",
    "               show_progress_bar = True)\n",
    "print()\n",
    "print(f'Best Score: {study.best_value*100:.3f} %')\n",
    "print()\n",
    "print(f'Best Params:')\n",
    "print(study.best_params)\n",
    "\n",
    "results = study.trials_dataframe()\n",
    "results['value'].sort_values().reset_index(drop=True).plot();\n",
    "plt.title('Convergence plot');\n",
    "plt.xlabel('Iteration');\n",
    "plt.ylabel('Score');\n",
    "\n",
    "chosen_param = {\n",
    "    i.replace(\"gbc_\", \"\"):j for i, j in zip(study.best_params.keys(), study.best_params.values())\n",
    "}\n",
    "print()\n",
    "print(chosen_param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
